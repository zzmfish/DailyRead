---
tags: 自动驾驶
---

#### <font color="orange">➢</font> 人工标注

一千余人的标注团队。

一个Clip由一段路程上的所有相机和传感器数据构成。

以4D空间（3D空间+时间维度）Vector Space 的 Clip 为最小标注单位。

#### <font color="orange">➢</font> 自动标注

服务器上的大模型，其精度和泛化能力往往强于车端的小模型。

多个大模型做 assemble 之后的精度和泛化也往往也强于单个大模型。

用集成模型标注数据，再用来训练小模型。

标注人员可以对机器标好的数据做最后的检查和修改。

得到在整个Clip上连续一致的稠密标注结果，同一个物体的标注在视频序列前后帧，以及不同相机的图像中均保持一致。

多次经过同一个地点，能够获得多个相同地点的Clip，一起进行更大规模的优化，得到更加精确和更加详细的标注结果，并且得到一个高精地图。

上帝视角：

* 过去和将来发生什么
* 每个目标运动轨迹的真值
* 解决遮挡问题


#### <font color="orange">➢</font> 数据仿真

1) 传感器模拟：相机传感器噪声、运动模糊、光学畸变、挡风玻璃上的衍射斑；

2) 逼真的渲染：神经渲染，光线追踪；

3) 场景及演员：<u>2000公里</u> 虚拟道路，形形色色的汽车和行人；

4) 大规模场景生成：使用机器学习算法找到容易出错的场景；

5) 场景重建：重建真实场景的Failure Case。



[阅读原文](https://mp.weixin.qq.com/s/60uAYOQ1f0Sq3XtVWsR3Pw)