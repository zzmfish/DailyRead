---
tags: 自动驾驶
---

毫米波雷达的数据一般以 Point Cloud（点云）的形式呈现。

毫米波雷达的点包括 X、Y（也可能有 Z）坐标，RCS（物体反射面积）和 Doppler（物体速度）。

<center>🌻🌻🌻</center>

## 基于 Point Cloud 的融合方法

#### 数据层融合

由一种传感器数据生成目标物体的 **候选（Proposal）**，然后在另外一种传感器数据上进行验证。

一个 **点** 就是一个物体 Proposal 或者对点云做一个简单的 **聚类**，每个类作为一个物体，然后将生成的 Proposal 从 **雷达坐标系**（一般是 Bird's Eye View, BEV）映射到 **图像坐标系**，并根据 Proposal 的距离来生成候选的 **Boundingbox**。最后就是用传统的基于 CNN 的方法来对 Proposal 进行分类。

更复杂一些的方法会先将点云转换成 BEV 坐标下的图像，采用基于 CNN 的物体检测网络生成 Proposal。

![](http://zhouzm.cn/DailyRead/assets/images/210731_%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88_DataLevelFusion.png)

#### 特征层融合

所谓融合就是使用深度学习的 Concatenation 操作，将来自多个输入的特征图叠放到一起，后续一般会采用 kernel 大小为 1 x 1 的卷积层对其进行 **压缩（加权平均）**。网络会自动的从训练数据中学习权重，从而达到融合多种特征的目的。特征融合模块输出的是 **特征图**。

传统毫米波雷达的点云数据非常稀疏，单帧的点云数据也是很难处理的，一般都需要 **在时序上进行融合**。

车辆正前方近处的物体其重要性要远大于侧面远处的物体，为了体现这种局部区域的重要性区别，可 **对特征图的不同位置进行加权**。

![](http://zhouzm.cn/DailyRead/assets/images/210731_%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88_%E7%9B%B8%E6%9C%BA%E5%9B%BE%E5%83%8F%E5%92%8C%E7%82%B9%E4%BA%91%E5%9B%BE%E5%83%8F.png)



![](http://zhouzm.cn/DailyRead/assets/images/210731_%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88_FeatureLevelFusion.png)

#### 决策层融合

![](http://zhouzm.cn/DailyRead/assets/images/210731_%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88_DecisionLevelFusion.png)

<center>🌻🌻🌻</center>

## 基于 RAD Tensor 的融合方法

Range-Azimuth-Doppler Tensor 利用深度神经网络处理 **雷达的底层数据**。

**RAD** 其实可以看作极坐标下的多通道图像，其通道是 Doppler 特征。

将 RAD 数据（极坐标）和图像数据都转换到 **BEV 坐标**（笛卡尔坐标系）下。

在时序上的对齐，可以雷达数据为基准，在时间轴上寻找距离其最近的图像数据。

![](http://zhouzm.cn/DailyRead/assets/images/210731_%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88_RAD%E5%92%8C%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2.png)

[阅读原文](https://mp.weixin.qq.com/s/hw5wN4yY0vl4rrMwqxa_bA)