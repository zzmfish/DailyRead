---
tags: 自动驾驶
---



## 前言

目前大多数预测方法将高精度地图渲染成颜色编码的属性，并且采用感受野有限的卷积神经网络对场景信息进行编码。

我们提出：

* 从矢量形式学习一个动态交通参与者和结构化场景的统一的表示
* 使用图神经网络来合并这些向量的集合
* 解码目标交通参与者输出的节点特征来预测它未来的运动轨迹

分层的图网络结构：

* 把具有相同折线ID，并且具有相同语义标签的向量整合成折线特征
* 所有不同的折线特征互相连通交换信息
* 通过多层感知器实现局部图，通过自注意力机制实现全局图

图像补全目标：

* 随机掩盖属于静态场景或是动态轨迹的节点特征
* 让模型重构被掩盖的特征

## 相关工作

## VectorNet方法

#### 表示轨迹和地图

大多数高精度地图的标注是以样条曲线（如车道线）、封闭形状（如交叉路口）和点（如红绿灯）的形式呈现，并且附带属性信息，如语义标签和当前状态（如交通灯的颜色，道路的速度限制）。对于动态交通参与者，他们的轨迹是关于时间的有向样条曲线的形式。所有这些元素元素都可以近似为矢量序列。

我们向量化的过程是一个在连续轨迹，地图标注和矢量集合之间的一对一的映射，虽然后者是无序的。这使我们可以在矢量集合上构建一个可以被图神经网络编码的图表示结构。更具体地说，我们将属于折线Pj的每一个向量vi看出图中的一个节点，节点特征如下：

$$
v_i=[d_i^s, d_i^e, a_i, j]
$$

其中dis和die是向量的起点和终点坐标，其可以表示为2D坐标（x,y）或是3D坐标（x,y,z）；ai对应属性特征，比如动态交通参与者的类型，轨迹的时间戳，或是道路特征的类型，或是车道线的速度限制。j是Pj的ID，表示vi属于Pj。

#### 构建折线子图

#### 用于高阶交互的全局图

#### 整体框架

## 实验

#### 实验设置

###### 数据集

###### 评价指标

###### 栅格图基准

#### 卷积网络基准的消融研究

#### VectorNet消融研究

#### 模型尺寸和计算量的比较

## 仿真与结果分析





[PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Gao_VectorNet_Encoding_HD_Maps_and_Agent_Dynamics_From_Vectorized_Representation_CVPR_2020_paper.pdf)

[阅读原文](https://www.auto-testing.net/news/show-108356.html)

